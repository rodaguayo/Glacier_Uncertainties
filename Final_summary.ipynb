{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192a8bfd-20a7-4d37-9556-9ecba759d641",
   "metadata": {},
   "source": [
    "# Dataset for Zenodo repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970de23-7bc7-44eb-b1e2-7a63079a41fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from oggm import utils\n",
    "from glob import glob\n",
    "\n",
    "# spatial\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "import xesmf as xe\n",
    "import regionmask\n",
    "\n",
    "# climate\n",
    "from xclim.indicators import atmos\n",
    "from xclim import core \n",
    "\n",
    "# others\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir('/home/rooda/Dropbox/Patagonia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3b1b4-391e-4004-bb47-031800400f01",
   "metadata": {},
   "source": [
    "## \"basins_boundaries.zip\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12061f5-03fc-44f8-b178-9212eb885c9d",
   "metadata": {},
   "source": [
    "Contains the polygons (in .shp format) of the studied catchments. Each catchment is identified by its \"basin_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ee063-0174-4f0d-919f-590c59d2437a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = gpd.read_file(\"GIS South/Basins_Patagonia_ice.shp\")\n",
    "basins = basins.set_index(\"ID\")\n",
    "\n",
    "names = [\"Yelcho\", \"Baker\", \"Santa Cruz\", \"Palena\", \"Grey\", \"Puelo\", \"Cisnes\", \"Aysen\", \"Pascua\"]\n",
    "basins.loc[basins.basin_area > 5000, \"Name\"] = names\n",
    "basins = basins.replace({\"Zone\": {1:'PPY', 2:'PCA', 3:'NPI-E', 4:'NPI-W', 5:'SPI-N', 6:'SPI-C', 7:'SPI-S', 8:'GCN', 9:'CDI'}})\n",
    "basins = basins[[\"Name\", \"Zone\", \"basin_area\", \"geometry\"]]\n",
    "basins = basins.rename(columns = {\"Name\": \"basin_name\", \"Zone\": \"basin_zone\"})\n",
    "\n",
    "basins.index.name='basin_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a4d99-f6d5-4a7a-97b5-f78d0b2b171f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins.to_file(\"MS2 Results/zenodo/basins_boundaries.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8cb71f-bbcc-417e-99bd-531692bf2e5c",
   "metadata": {},
   "source": [
    "## \"dataset_historical.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83e26e-6ad4-4bb3-b36d-f800fd8bc693",
   "metadata": {},
   "source": [
    "Summarises the historical conditions of each glacier at the catchment scale (area, volume and reference climate): \n",
    "- `basin_id`: unique identifier for each catchment \n",
    "- `basin_name`: basin name (only for catchments with area over 5000 lm2)\n",
    "- `basin_zone`: hydrological zone of each basin (9 in total)\n",
    "- `basin_area`: area of the basin in km2\n",
    "- `n_RGIX`: number of glaciers according to RGI6 and RGI7 inventories.\n",
    "- `area_RGIX`: glacier area in km2 according to inventories RGI6 and RGI7\n",
    "- `vol_F19`: glacier volume in km3 estimated from Farinnoti et al. (2019)\n",
    "- `vol_M22`: : glacier volume in km3 estimated according to Millan et al. (2022)\n",
    "- `PP_X`: annual mean precipitation (estimated only using glacierized grid cells) according to PMET v1.0, ERA5, MSWEP v2.8 and CR2MET v2.5 (1980-2015)\n",
    "- `T2M_X`: annual mean temperature (estimated only using glacierized grid cells) according to PMET v1.0, ERA5, MSWEP v2.8 and CR2MET v2.5 (1980-2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa357f-c6a9-4e9f-b07f-fd4566977dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add area, volume and number of glaciers\n",
    "RGI6 = gpd.read_file(\"GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI7 = gpd.read_file(\"GIS South/Glaciers/RGI7_v2.shp\")\n",
    "glaciers  = pd.concat([RGI6.geometry, RGI7.geometry])\n",
    "glaciers  = glaciers.buffer(0.05) # mask to use for baseline climate\n",
    "\n",
    "RGI6_sum = RGI6.groupby(\"ID_basin\")[[\"O2Region\", \"area_km2\", \"vol_F19\", \"vol_M22\"]].sum()\n",
    "RGI6_sum = RGI6_sum.rename(columns = {\"O2Region\": \"n_RGI6\", \"area_km2\": \"area_RGI6\"})\n",
    "\n",
    "RGI7_sum = RGI7.groupby(\"ID_basin\")[[\"O2Region\", \"area_km2\"]].sum()\n",
    "RGI7_sum = RGI7_sum.rename(columns = {\"O2Region\": \"n_RGI7\", \"area_km2\": \"area_RGI7\"})\n",
    "\n",
    "basins = pd.concat([basins, RGI6_sum, RGI7_sum], axis=1)\n",
    "\n",
    "# fill with zeros\n",
    "fillc = [\"n_RGI6\", \"area_RGI6\", \"vol_F19\", \"vol_M22\", \"n_RGI7\", \"area_RGI7\"]\n",
    "basins[fillc] = basins[fillc].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d4d41-c4ff-4647-93c3-310610b013dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original (no regrid) reference climate (1980-2019): \n",
    "pp_pmet  = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_pmet = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").temp\n",
    "dem_005  = xr.open_dataset(\"/home/rooda/OGGM_results/PMET_OGGM_1980_2019m.nc\").hgt\n",
    "\n",
    "pp_cr2met  = xr.open_dataset(\"/home/rooda/OGGM_results/CR2MET_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_cr2met = xr.open_dataset(\"/home/rooda/OGGM_results/CR2MET_OGGM_1980_2019m.nc\").temp\n",
    "\n",
    "pp_mswep  = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_mswep = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").temp\n",
    "dem_010   = xr.open_dataset(\"/home/rooda/OGGM_results/MSWEP_OGGM_1980_2019m.nc\").hgt\n",
    "regridder = xe.Regridder(dem_010,   dem_005, \"nearest_s2d\")\n",
    "dem_010   = regridder(dem_010)\n",
    "\n",
    "pp_era5   = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").prcp\n",
    "t2m_era5  = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").temp\n",
    "dem_025   = xr.open_dataset(\"/home/rooda/OGGM_results/ERA5_OGGM_1980_2019m.nc\").hgt\n",
    "regridder = xe.Regridder(dem_025,   dem_005, \"nearest_s2d\")\n",
    "dem_025   = regridder(dem_025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea3fcb-6d5a-4d64-923b-29182e60fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid (PMET as the reference grid; 0.05º)\n",
    "\n",
    "regridder  = xe.Regridder(pp_era5,   pp_pmet, \"nearest_s2d\")\n",
    "pp_era5    = regridder(pp_era5)\n",
    "regridder  = xe.Regridder(pp_cr2met, pp_pmet, \"nearest_s2d\")\n",
    "pp_cr2met  = regridder(pp_cr2met)\n",
    "regridder  = xe.Regridder(pp_mswep,  pp_pmet, \"nearest_s2d\")\n",
    "pp_mswep   = regridder(pp_mswep)\n",
    "\n",
    "lapse_rate = 0.0065 \n",
    "\n",
    "regridder  = xe.Regridder(t2m_era5,   t2m_pmet, \"nearest_s2d\")\n",
    "t2m_era5   = regridder(t2m_era5) # fake high res\n",
    "factor     = (dem_025 - dem_005)*lapse_rate\n",
    "t2m_era5   =  t2m_era5 + factor # \"real\" high res\n",
    "\n",
    "regridder  = xe.Regridder(t2m_mswep,   t2m_pmet, \"nearest_s2d\")\n",
    "t2m_mswep  = regridder(t2m_mswep) # fake high res\n",
    "factor     = (dem_010 - dem_005)*lapse_rate\n",
    "t2m_mswep  =  t2m_mswep + factor # \"real\" high res\n",
    "\n",
    "regridder  = xe.Regridder(t2m_cr2met, t2m_pmet, \"bilinear\")\n",
    "t2m_cr2met = regridder(t2m_cr2met) # simple case (same resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8099d-1885-43f6-bd81-e10f1ee62090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mask: only glaciarated area\n",
    "mask      = regionmask.mask_geopandas(glaciers, pp_pmet)   >= 0\n",
    "\n",
    "pp_pmet    = pp_pmet.where(mask, drop = True)\n",
    "pp_era5    = pp_era5.where(mask, drop = True)\n",
    "pp_cr2met  = pp_cr2met.where(mask, drop = True)\n",
    "pp_mswep   = pp_mswep.where(mask, drop = True)\n",
    "\n",
    "t2m_pmet   = t2m_pmet.where(mask, drop = True)\n",
    "t2m_era5   = t2m_era5.where(mask, drop = True)\n",
    "t2m_cr2met = t2m_cr2met.where(mask, drop = True)\n",
    "t2m_mswep  = t2m_mswep.where(mask, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a69521-f549-4434-8916-e991f04bea0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate more variables\n",
    "\n",
    "# xclim needs the units\n",
    "pp_pmet.attrs['units']   = \"mm month-1\"\n",
    "pp_era5.attrs['units']   = \"mm month-1\"\n",
    "pp_cr2met.attrs['units'] = \"mm month-1\"\n",
    "pp_mswep.attrs['units']  = \"mm month-1\"\n",
    "t2m_pmet.attrs['units']   = \"C\"\n",
    "t2m_era5.attrs['units']   = \"C\"\n",
    "t2m_cr2met.attrs['units'] = \"C\"\n",
    "t2m_mswep.attrs['units']  = \"C\"\n",
    "\n",
    "# Positive degree-day sum (PDD)\n",
    "ppd_pmet   = t2m_pmet.where(t2m_pmet >= -1)\n",
    "ppd_era5   = t2m_era5.where(t2m_era5 >= -1)\n",
    "ppd_cr2met = t2m_cr2met.where(t2m_cr2met >= -1)\n",
    "ppd_mswep  = t2m_mswep.where(t2m_mswep >= -1)\n",
    "\n",
    "# snowfall component\n",
    "prsn_pmet = atmos.snowfall_approximation(pp_pmet, t2m_pmet, method='brown', thresh='0 degC')\n",
    "prsn_pmet = core.units.convert_units_to(prsn_pmet, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_era5 = atmos.snowfall_approximation(pp_era5, t2m_era5, method='brown', thresh='0 degC')\n",
    "prsn_era5 = core.units.convert_units_to(prsn_era5, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_cr2met = atmos.snowfall_approximation(pp_cr2met, t2m_cr2met, method='brown', thresh='0 degC')\n",
    "prsn_cr2met = core.units.convert_units_to(prsn_cr2met, target = 'mm month-1', context = \"hydro\")\n",
    "prsn_mswep = atmos.snowfall_approximation(pp_mswep, t2m_mswep, method='brown', thresh='0 degC')\n",
    "prsn_mswep = core.units.convert_units_to(prsn_mswep, target = 'mm month-1', context = \"hydro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88542bd-3ce9-4662-aa02-d8a4d05ce028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annual value\n",
    "pp_pmet    = pp_pmet.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_era5    = pp_era5.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_cr2met  = pp_cr2met.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "pp_mswep   = pp_mswep.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "prsn_pmet    = prsn_pmet.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_era5    = prsn_era5.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_cr2met  = prsn_cr2met.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "prsn_mswep   = prsn_mswep.resample(time='1Y').sum(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "t2m_pmet   = t2m_pmet.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_era5   = t2m_era5.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_cr2met = t2m_cr2met.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "t2m_mswep  = t2m_mswep.resample(time='1Y').mean(skipna = False).mean(dim=\"time\")\n",
    "\n",
    "# the +1 es due to threshold of -1ºC\n",
    "ppd_pmet   = (ppd_pmet   + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_era5   = (ppd_era5   + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_cr2met = (ppd_cr2met + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "ppd_mswep  = (ppd_mswep  + 1).resample(time='1Y').sum(skipna = True).mean(dim=\"time\")\n",
    "\n",
    "ppd_pmet   = ppd_pmet.where(ppd_pmet > 0) * 30 # from monthly to daily (doesnt change anything)\n",
    "ppd_era5   = ppd_era5.where(ppd_era5 > 0) * 30\n",
    "ppd_cr2met = ppd_cr2met.where(ppd_cr2met > 0) * 30\n",
    "ppd_mswep  = ppd_mswep.where(ppd_mswep > 0) * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe52ef2-de4b-45f1-9d2d-81078ae65543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean value for each catchment\n",
    "averager   = xe.SpatialAverager(pp_pmet,   basins.geometry, geom_dim_name=\"avg\")\n",
    "\n",
    "basins[\"PP_PMET\"]   = averager(pp_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_ERA5\"]   = averager(pp_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_CR2MET\"] = averager(pp_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PP_MSWEP\"]  = averager(pp_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"PRSN_PMET\"]   = averager(prsn_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_ERA5\"]   = averager(prsn_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_CR2MET\"] = averager(prsn_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PRSN_MSWEP\"]  = averager(prsn_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"T2M_PMET\"]   = averager(t2m_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_ERA5\"]   = averager(t2m_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_CR2MET\"] = averager(t2m_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2M_MSWEP\"]  = averager(t2m_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"PPD_PMET\"]   = averager(ppd_pmet,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_ERA5\"]   = averager(ppd_era5,   skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_CR2MET\"] = averager(ppd_cr2met, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"PPD_MSWEP\"]  = averager(ppd_mswep,  skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fa77a-7893-43ba-8db3-bcdd5a1b1f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins = basins.drop(columns = \"geometry\").to_csv(\"MS2 Results/zenodo/dataset_historical.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e837011-ec42-4333-9869-d7751d10159d",
   "metadata": {},
   "source": [
    "## \"dataset_future.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8413cf-7c65-4644-81e0-d3d501457203",
   "metadata": {},
   "source": [
    "Summarises the future glacier climate drivers and their impacts at the catchment scale: \n",
    "- `basin_id`: unique identifier for each catchment \n",
    "- `PPc_sspX`: precipitation change (in %) between the periods 1980-2015 and 2070-2099. Each column represents a different SSP scenario.\n",
    "- `T2Mc_sspX`: temperature change (in ºC) between the periods 1980-2015 and 2070-2099. Each column represents a different SSP scenario.\n",
    "- `mass_loss_sspX`: mean volume loss in 2100 for each catchment. Each column represents a different SSP scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1529b0c-b066-4da3-be02-baa351f45ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_coords = np.arange(-56,-40, 0.5)\n",
    "lon_coords = np.arange(-76,-67, 0.5)\n",
    "\n",
    "baseline_period = slice(\"1980-01-01\", \"2015-01-01\")\n",
    "future_period   = slice(\"2070-01-01\", \"2100-01-01\")\n",
    "\n",
    "gcm_list  = [\"ACCESS-CM2\", \"BCC-CSM2-MR\", \"CMCC-ESM2\", \"FGOALS-f3-L\", \"GFDL-ESM4\", \"CMCC-CM2-SR5\", \"KACE-1-0-G\", \"MPI-ESM1-2-HR\", \"MRI-ESM2-0\", \"MIROC6\"]\n",
    "ssp_list  = ['ssp126', 'ssp245', 'ssp370', 'ssp585']\n",
    "\n",
    "results_pp = []\n",
    "results_t2m = []\n",
    "\n",
    "for ssp in tqdm(ssp_list):\n",
    "    \n",
    "    results_gcm_pp  = []\n",
    "    results_gcm_t2m = []\n",
    "    \n",
    "    for gcm in gcm_list:\n",
    "        \n",
    "        pp_model_ssp = xr.open_dataset(\"/home/rooda/OGGM_results/Future_climate/PP_\" + gcm + \"_\" + ssp + \".nc\")[\"pr\"]\n",
    "        pp_model_ssp = pp_model_ssp.interp(lat = lat_coords, lon = lon_coords)\n",
    "        pp_model_ssp = core.units.convert_units_to(pp_model_ssp, target = 'mm month-1', context = \"hydro\").resample(time = \"YS\").sum()\n",
    "        pp_change    = (pp_model_ssp.sel(time = future_period).mean(dim=\"time\") / pp_model_ssp.sel(time = baseline_period).mean(dim=\"time\"))-1\n",
    "        results_gcm_pp.append(pp_change)\n",
    "        \n",
    "        t2m_model_ssp = xr.open_dataset(\"/home/rooda/OGGM_results/Future_climate/T2M_\" + gcm + \"_\" + ssp + \".nc\")[\"tas\"]\n",
    "        t2m_model_ssp = t2m_model_ssp.interp(lat = lat_coords, lon = lon_coords)\n",
    "        t2m_model_ssp = t2m_model_ssp.resample(time='YS').mean()        \n",
    "        t2m_change    = t2m_model_ssp.sel(time = future_period).mean(dim=\"time\") - t2m_model_ssp.sel(time = baseline_period).mean(dim=\"time\")\n",
    "        results_gcm_t2m.append(t2m_change)\n",
    "        \n",
    "    results_gcm_pp  = xr.concat(results_gcm_pp,  dim='gcm')\n",
    "    results_gcm_t2m = xr.concat(results_gcm_t2m, dim='gcm')\n",
    "    results_pp.append(results_gcm_pp)\n",
    "    results_t2m.append(results_gcm_t2m)\n",
    "    \n",
    "dataset = xr.merge([xr.concat(results_pp,  dim='ssp'), \n",
    "                    xr.concat(results_t2m, dim='ssp')])\n",
    "\n",
    "# GCM uncertainty (SSP 245) > 80% of the models should agree the direction\n",
    "gcm_spread = dataset.pr[2].where(dataset.pr[1] >= 0, 1).where(dataset.pr[2] < 0, -1).sum(dim = \"gcm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce783d2-dbed-4f20-bed8-90dd03eb0db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## resample using ESMF.RegridMethod.NEAREST_STOD\n",
    "regridder  = xe.Regridder(dataset,  pp_pmet, \"bilinear\")\n",
    "dataset    = regridder(dataset)\n",
    "gcm_spread = regridder(gcm_spread)\n",
    "\n",
    "# only glacier area\n",
    "mask    = regionmask.mask_geopandas(glaciers, dataset)   >= 0\n",
    "dataset = dataset.where(mask, drop = True)\n",
    "gcm_spread = gcm_spread.where(mask, drop = True)\n",
    "\n",
    "# multi-model mean\n",
    "dataset = dataset.mean(dim = \"gcm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e103e49-92f7-4ebf-8693-5f33fe1f7e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select SSP 245 for map (a,b)\n",
    "savg  = xe.SpatialAverager(dataset,  basins.geometry, geom_dim_name=\"avg\")\n",
    "\n",
    "basins[\"PPc_ssp126\"] = savg(dataset.pr[0], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp245\"] = savg(dataset.pr[1], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp370\"] = savg(dataset.pr[2], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_ssp585\"] = savg(dataset.pr[3], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values*100\n",
    "basins[\"PPc_spread\"]     = savg(gcm_spread, skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "\n",
    "basins[\"T2Mc_ssp126\"] = savg(dataset.tas[0], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp245\"] = savg(dataset.tas[1], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp370\"] = savg(dataset.tas[2], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values\n",
    "basins[\"T2Mc_ssp585\"] = savg(dataset.tas[3], skipna=True).assign_coords(avg=xr.DataArray(basins.index, dims=(\"avg\",))).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69f89f-e5f6-4793-b7d8-c875def09271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# volume change\n",
    "RGI6_ids = RGI6[RGI6.area_km2 > 1][[\"RGIId\", \"ID_basin\"]]\n",
    "RGI7_ids = RGI7[RGI7.area_km2 > 1]\n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'ID_basin' : 'ID_basin'})\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "# merge both datasets\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")\n",
    "\n",
    "def preprocess(ds): # remove unnecessary variables and coordinates\n",
    "    return ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])['volume']\n",
    "\n",
    "gdirs = glob(\"/home/rooda/OGGM_results/new/*\", recursive = True)\n",
    "\n",
    "ds    = []\n",
    "for gdir in tqdm(gdirs):\n",
    "\n",
    "    # read historical run \n",
    "    model_hist   = xr.open_mfdataset(gdir + \"/run_outputs_*.nc\", preprocess = preprocess)\n",
    "    model_hist   = model_hist.sel(time=2015).volume # check NAs\n",
    "\n",
    "    paths = glob(gdir + \"/run_output_*ssp*.nc\", recursive = True)\n",
    "    for path in tqdm(paths, leave = False):\n",
    "\n",
    "        # read future run and concatenate\n",
    "        model_future = xr.open_dataset(path)\n",
    "        model_future = preprocess(model_future).sel(time=2100)\n",
    "        model   = xr.concat([model_hist, model_future], dim = \"time\").load()\n",
    "\n",
    "        # add basin ID to each glacier ID (RGI_ID)\n",
    "        ids_subset = ids[ids.index.isin(model.rgi_id.to_pandas().tolist())]\n",
    "        model = model.assign_coords(rgi_id = ids_subset.ID_basin.tolist())\n",
    "        model = model.groupby('rgi_id').sum()\n",
    "        model = 1 - (model.sel(time = 2100) / model.sel(time = 2015))\n",
    "        \n",
    "        # ID of the setup\n",
    "        experiment_id = pd.Series(data = {'SSP':     os.path.basename(path).split(\"_\")[3]})\n",
    "        ds_model = pd.DataFrame(pd.concat([experiment_id, model.to_pandas()]), columns=['mass_loss']).transpose()\n",
    "        ds.append(ds_model)\n",
    "        \n",
    "ds = pd.concat(ds)\n",
    "ds = ds.groupby(\"SSP\").mean()\n",
    "ds = ds.transpose()\n",
    "ds = ds.rename(columns = {'ssp126': 'mass_loss_ssp126', 'ssp245': 'mass_loss_ssp245',\n",
    "                          'ssp370': 'mass_loss_ssp370', 'ssp585': 'mass_loss_ssp585'})\n",
    "basins\n",
    "basins = pd.concat([basins, ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306999a8-d413-4edb-bd70-1afe980e5f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins = basins[[\"basin_name\",\n",
    "                 'PPc_ssp126', 'PPc_ssp245', 'PPc_ssp370', 'PPc_ssp585', \"PPc_spread\", \n",
    "                 'T2Mc_ssp126','T2Mc_ssp245', 'T2Mc_ssp370', 'T2Mc_ssp585',\n",
    "                 'mass_loss_ssp126', 'mass_loss_ssp245', 'mass_loss_ssp370', 'mass_loss_ssp585']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f669064-834a-400b-bb69-b1952f48b5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basins\n",
    "basins = basins.to_csv(\"MS2 Results/zenodo/dataset_future.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab484a7d-fd6f-4b9a-8a63-1df81714e75a",
   "metadata": {},
   "source": [
    "## \"dataset_signatures.csv\" file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c68644-13e4-44a3-bb29-974063688e6b",
   "metadata": {},
   "source": [
    "Summarises the  glacio-hydrological signatures for each catchment. The metrics are calculated for the variables \"glacier runoff (tr)\" and \"glacier melt (mg)\". The main source of uncertainty in each catchment was the source that accumulated most RMSE loss. Details of the different metrics can be found in Table 1 in the MS. \n",
    "- `basin_id`: unique identifier for each catchment \n",
    "- `variable_interannual_var`: Inter-annual variability (mm yr-1). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_lt_change`: Long-term trend (% dec-1).  The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_lt_trend`: Long-term change (%).  The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_peak_water_duration`:\tPeak water duration (years).  The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_peak_water_magnitude`: Peak water magnitude (mm yr-1).  The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_peak_water_year`: Peak water year (date, year). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_ref_magnitude`: Reference magnitude (mm yr-1). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_seasonal_cont`: Seasonal contribution (%). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_seasonal_shift`: Seasonal shift (%). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `variable_seasonal_var`: Seasonal variability (%). The value represent the mean obtained from the complete ensemble of scenarios (n = 1920).\n",
    "- `SoU_variable_interannual_var`: Main source of uncertainty of the inter-annual variability for each catchment.\n",
    "- `SoU_variable_lt_change`:  Main source of uncertainty of the long-term trend for each catchment.\n",
    "- `SoU_variable_lt_trend`:  Main source of uncertainty of the long-term change for each catchment.\n",
    "- `SoU_variable_peak_water_duration`:  Main source of uncertainty of the peak water duration for each catchment.\n",
    "- `SoU_variable_peak_water_magnitude`:  Main source of uncertainty of the peak water magnitude for each catchment.\n",
    "- `SoU_variable_peak_water_year`:  Main source of uncertainty of the peak water year for each catchment.\n",
    "- `SoU_variable_ref_magnitude`:  Main source of uncertainty of the reference magnitude for each catchment.\n",
    "- `SoU_variable_seasonal_cont`:  Main source of uncertainty of the seasonal contribution for each catchment.\n",
    "- `SoU_variable_seasonal_shift`:  Main source of uncertainty of the seasonal shift for each catchment.\n",
    "- `SoU_variable_seasonal_var`:  Main source of uncertainty of the seasonal variability for each catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048abeab-0209-4cdb-ab00-c9a1167efc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glacio-hydrological signature\n",
    "metrics = pd.read_csv(\"MS2 Results/dataset_hydro_signatures.csv\")\n",
    "metrics = metrics.drop(columns = [\"Outline\", \"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"])\n",
    "metrics = metrics.rename(columns = {\"Unnamed: 0\": \"variable\", \"Variable\": \"metric\"})\n",
    "metrics = metrics.groupby([\"metric\", \"variable\"]).mean().transpose()\n",
    "metrics = metrics.droplevel(0, axis=1) \n",
    "metrics.columns = np.concatenate((\"mg_\" + metrics.columns[0:10].values, \"tr_\" + metrics.columns[0:10].values), axis=0)\n",
    "metrics.index = metrics.index.astype(\"int64\")\n",
    "\n",
    "metrics_su = pd.read_csv(\"MS2 Results/feature_importance_rmse.csv\", index_col = 0)\n",
    "metrics_su['Most_important'] = metrics_su[[\"Outline\",\"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"]].idxmax(axis=1)\n",
    "metrics_su = metrics_su.drop(columns = [\"Outline\", \"Climate\", \"Volume\", \"GCM\", \"SSP\", \"BCM\"])\n",
    "metrics_su = metrics_su.pivot(columns = [\"Variable\", \"Metric\"], values = \"Most_important\")\n",
    "metrics_su = metrics_su.droplevel(0, axis=1)\n",
    "metrics_su.columns = np.concatenate((\"SoU_mg_\" + metrics_su.columns[0:10].values, \"SoU_tr_\" + metrics_su.columns[0:10].values), axis=0)\n",
    "\n",
    "metrics_hydro = pd.concat([metrics, metrics_su], axis=1)\n",
    "metrics_hydro.to_csv(\"MS2 Results/zenodo/dataset_signatures.csv\",  index_label='basin_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e9258-3f79-4817-89e6-46de04278607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
