{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f023dea2-3a0c-4e52-b248-33ff045d6ea9",
   "metadata": {},
   "source": [
    "# Calculation of all signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10885fd0-3cf4-4958-ade7-81c84c48e333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import geopandas as gpd\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from glob import glob\n",
    "from oggm import utils\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir('/home/rooda/OGGM_results/')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', np.RankWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27eeb3-35c3-47e5-9031-6a566ffdc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds): \n",
    "    ds = ds.drop_vars(['hydro_year', 'hydro_month', 'calendar_year', 'calendar_month'])\n",
    "    \n",
    "    # hydro-variables \n",
    "    ds[\"total_runoff\"] = (ds.melt_off_glacier + ds.melt_on_glacier + ds.liq_prcp_off_glacier + ds.liq_prcp_on_glacier)*1e-3 # m3/yr\n",
    "    ds[\"total_runoff_monthly\"] = ((ds.melt_off_glacier_monthly + ds.melt_on_glacier_monthly + ds.liq_prcp_off_glacier_monthly + ds.liq_prcp_on_glacier_monthly)*1e-3)/(30*86400) # in m3/s\n",
    "    ds[\"melt_on_glacier\"] = (ds.melt_on_glacier)*1e-3 # in # m3/yr\n",
    "    ds[\"melt_on_glacier_monthly\"] = ((ds.melt_on_glacier_monthly)*1e-3)/(30*86400) # in m3/s\n",
    "    return ds[save_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f65d16-c588-46ff-ab27-064dc6ba8a19",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893e9b0-f469-4ed9-9dc1-9ef52e8a089f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RGI6_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI6_v2.shp\")\n",
    "RGI6_ids = RGI6_ids[RGI6_ids.area_km2 > 1][[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "RGI7_ids = gpd.read_file(\"/home/rooda/Dropbox/Patagonia/GIS South/Glaciers/RGI7_v2.shp\")\n",
    "RGI7_ids = RGI7_ids[RGI7_ids.area_km2 > 1]\n",
    "RGI7_ids = utils.cook_rgidf(RGI7_ids, o1_region='17', o2_region='02', bgndate= RGI7_ids.src_date, \n",
    "                            version = \"70\", assign_column_values= {'Zone' : 'Zone', 'ID_basin' : 'ID_basin'})\n",
    "RGI7_ids = RGI7_ids[[\"RGIId\", \"ID_basin\"]]\n",
    "\n",
    "# merge both datasets\n",
    "ids = pd.concat([RGI6_ids, RGI7_ids]).set_index(\"RGIId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1a9b2-446d-47bf-869c-448b84a449d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# area in m2\n",
    "basins = gpd.read_file(\"zip:////home/rooda/Dropbox/Patagonia/MS2 Results/zenodo/basins_boundaries.zip\")\n",
    "basins[\"rgi_id\"] = basins.basin_id.astype(\"int64\") # to have the same ids with glaciers/catchments\n",
    "basins = basins.set_index(\"rgi_id\") \n",
    "basins = basins.basin_area.to_xarray() * 1e6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bdf8a-a8d9-45fc-87cd-be78cb5e90a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove unnecessary variables and coordinates\n",
    "save_variables = [\"melt_on_glacier\", \"melt_on_glacier_monthly\", \"total_runoff\", \"total_runoff_monthly\"]\n",
    "\n",
    "ref_period = slice(\"1980-01-01\", \"2014-12-31\") \n",
    "future_period = slice(\"2070-01-01\", \"2099-12-31\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d280566-50bc-46b4-873b-a88f0db3288d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculation of all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628fbf5e-c9e3-44d0-aded-d30008d1ea8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Folder with all the results\n",
    "gdirs = glob(\"/home/rooda/OGGM_results/runs/*\", recursive = True)\n",
    "gdirs = [a for a in gdirs if os.path.isdir(a)]\n",
    "\n",
    "variables = [\"melt_on_glacier\", \"total_runoff\"]\n",
    "\n",
    "ds_ref_magnitude        = []\n",
    "ds_peak_water_year      = []\n",
    "ds_peak_water_magnitude = []\n",
    "ds_peak_water_duration  = []\n",
    "ds_interannual_var      = []\n",
    "ds_seasonal_cont        = []\n",
    "ds_seasonal_var         = []\n",
    "ds_seasonal_shift       = []\n",
    "ds_lt_trend             = []\n",
    "ds_lt_change            = []\n",
    "\n",
    "for variable in tqdm(variables):\n",
    "    for gdir in tqdm(gdirs):\n",
    "\n",
    "        # read historical run \n",
    "        model_hist  = xr.open_dataset(glob(gdir + \"/run_outputs_*.nc\", recursive = False)[0])\n",
    "        model_hist  = preprocess(model_hist)\n",
    "        model_hist  = model_hist.drop_sel(time=[1980, 2020]) # check NAs\n",
    "\n",
    "        paths = glob(gdir + \"/run_output_*ssp*.nc\", recursive = True)\n",
    "        for path in tqdm(paths, leave = False):\n",
    "\n",
    "            # read future run and concatenate\n",
    "            model_future = xr.open_dataset(path)\n",
    "            model_future = preprocess(model_future)\n",
    "            model   = xr.concat([model_hist, model_future], dim = \"time\")\n",
    "\n",
    "            # add basin ID to each glacier ID (RGI_ID)\n",
    "            ids_subset = ids[ids.index.isin(model.rgi_id.to_pandas().tolist())]\n",
    "            model = model.assign_coords(rgi_id = ids_subset.ID_basin.tolist())\n",
    "            basin_area = basins[basins.rgi_id.isin(ids_subset.ID_basin)]\n",
    "            \n",
    "            # aggregate based on \"new\" ID\n",
    "            model = model.groupby('rgi_id').sum()\n",
    "            model = model.drop_sel(time=2099)\n",
    "\n",
    "            # ID of the setup\n",
    "            experiment_id = pd.Series(data = {'Variable': variable,\n",
    "                                              'Outline': os.path.basename(gdir).split(\"_\")[0],\n",
    "                                              'Climate': os.path.basename(gdir).split(\"_\")[1],\n",
    "                                              'Volume':  os.path.basename(gdir).split(\"_\")[2],\n",
    "                                              'GCM':     os.path.basename(path).split(\"_\")[2],\n",
    "                                              'SSP':     os.path.basename(path).split(\"_\")[3],\n",
    "                                              'BCM':     os.path.basename(path).split(\"_\")[4][0:3]})\n",
    "\n",
    "            ## 1. Reference magnitude (mm yr-1)\n",
    "            ref_magnitude = model[variable].sel(time = ref_period).mean(dim = \"time\").to_series()\n",
    "            ref_magnitude = (ref_magnitude / basin_area) * 1e3 # from m to mm \n",
    "            ref_magnitude = pd.DataFrame(pd.concat([experiment_id, ref_magnitude]), columns=['ref_magnitude']).transpose()\n",
    "            ds_ref_magnitude.append(ref_magnitude)\n",
    "            \n",
    "            # the following metrics are based on a 11-year moving average\n",
    "            rolling = model[variable].rolling(time=11, center=True).mean()\n",
    "\n",
    "            ## 2. Peak water year (years)\n",
    "            peak_water_year = rolling.idxmax(dim = \"time\").astype(\"int16\").to_series()      \n",
    "            peak_water_year = pd.DataFrame(pd.concat([experiment_id, peak_water_year]), columns=['peak_water_year']).transpose()\n",
    "            ds_peak_water_year.append(peak_water_year)\n",
    "\n",
    "            ## 3. Peak water magnitude (mm yr-1)\n",
    "            peak_water_magnitude = rolling.max(dim = \"time\")\n",
    "            peak_water_magnitude = (peak_water_magnitude / basin_area) * 1e3 # from m to mm \n",
    "            peak_water_magnitude = peak_water_magnitude.to_series()      \n",
    "            peak_water_magnitude = pd.DataFrame(pd.concat([experiment_id, peak_water_magnitude]), columns=['peak_water_magnitude']).transpose()\n",
    "            ds_peak_water_magnitude.append(peak_water_magnitude)\n",
    "\n",
    "            ## 4. Peak water duration (years)\n",
    "            peak_water_duration = 0.9 * rolling.max(dim = \"time\")\n",
    "            peak_water_duration = (rolling > peak_water_duration).sum(dim = \"time\").to_series()\n",
    "            peak_water_duration = pd.DataFrame(pd.concat([experiment_id, peak_water_duration]), columns=['peak_water_duration']).transpose()\n",
    "            ds_peak_water_duration.append(peak_water_duration)\n",
    "            \n",
    "            ## 5. Inter-annual variability (mm yr-1)\n",
    "            interannual_var = model[variable] - rolling # detreting\n",
    "            interannual_var = (interannual_var / basin_area) * 1e3 # from m to mm \n",
    "            interannual_var = interannual_var.std(dim = \"time\").to_series()\n",
    "            interannual_var = pd.DataFrame(pd.concat([experiment_id, interannual_var]), columns=['interannual_var']).transpose()\n",
    "            ds_interannual_var.append(interannual_var)\n",
    "            \n",
    "            ## 6. Seasonal contribution (%)\n",
    "            seasonal_cont = model[variable + \"_monthly\"].sel(time = ref_period)\n",
    "            seasonal_cont = seasonal_cont.mean(dim = \"time\")\n",
    "            seasonal_cont = seasonal_cont.sel(month_2d = [12,1,2]).sum(dim = \"month_2d\") / seasonal_cont.sum(dim = \"month_2d\")\n",
    "            seasonal_cont = seasonal_cont.to_series() * 100 # in percentage\n",
    "            seasonal_cont = pd.DataFrame(pd.concat([experiment_id, seasonal_cont]), columns=['seasonal_cont']).transpose()\n",
    "            ds_seasonal_cont.append(seasonal_cont)\n",
    "            \n",
    "            # 7. Seasonal variability (%)\n",
    "            seasonal_var = model[variable + \"_monthly\"].sel(time = ref_period)\n",
    "            seasonal_var = seasonal_var.sel(month_2d = [12,1,2]).sum(dim = \"month_2d\") / seasonal_var.sum(dim = \"month_2d\")\n",
    "            seasonal_var = seasonal_var.std(dim = \"time\").to_series() * 100 # in percentage\n",
    "            seasonal_var = pd.DataFrame(pd.concat([experiment_id, seasonal_var]), columns=['seasonal_var']).transpose()\n",
    "            ds_seasonal_var.append(seasonal_var)\n",
    "            \n",
    "            ## 8. Seasonal shift (%)\n",
    "            seasonal_shift = model[variable + \"_monthly\"]\n",
    "            seasonal_shift = seasonal_shift.sel(month_2d = [12,1,2]).sum(dim = \"month_2d\") / seasonal_shift.sum(dim = \"month_2d\")\n",
    "            seasonal_shift = seasonal_shift.sel(time = ref_period).mean(dim = \"time\") - seasonal_shift.sel(time = future_period).mean(dim = \"time\")\n",
    "            seasonal_shift = seasonal_shift.to_series() * 100 # in percentage\n",
    "            seasonal_shift = pd.DataFrame(pd.concat([experiment_id, seasonal_shift]), columns=['seasonal_shift']).transpose()\n",
    "            ds_seasonal_shift.append(seasonal_shift)\n",
    "            \n",
    "            ## 9. Long-term trend (% dec-1)\n",
    "            rolling_norm = rolling/rolling.max(dim = \"time\")  # normalize values (max = 1)\n",
    "            rolling_norm = rolling_norm.transpose(\"rgi_id\", \"time\") # trick to complete loop\n",
    "\n",
    "            lt_trend = []\n",
    "            for catchment in model.rgi_id.to_numpy(): # get the trend for each catchment\n",
    "\n",
    "                time_period = slice(int(peak_water_year[catchment].iloc[0]), int(peak_water_year[catchment].iloc[0])+30)\n",
    "                lt_trend_i = rolling_norm.sel(time = time_period, rgi_id = catchment)\n",
    "                lt_trend_i = lt_trend_i.polyfit(dim = \"time\", deg = 1, skipna = True).polyfit_coefficients[0].to_numpy()\n",
    "                lt_trend_i = lt_trend_i * 100 * 10 # final value: %% per decade\n",
    "                lt_trend.append(lt_trend_i)\n",
    "\n",
    "            lt_trend = pd.Series(lt_trend, index=model.rgi_id.to_numpy())\n",
    "            lt_trend = pd.DataFrame(pd.concat([experiment_id, lt_trend]), columns=['lt_trend']).transpose()\n",
    "            ds_lt_trend.append(lt_trend)\n",
    "            \n",
    "            ## 10. Long-term change\n",
    "            lt_change = model[variable].sel(time = future_period).mean(dim = \"time\") / model[variable].sel(time = ref_period).mean(dim = \"time\")\n",
    "            lt_change = (lt_change-1).to_series() * 100\n",
    "            lt_change = pd.DataFrame(pd.concat([experiment_id, lt_change]), columns=['lt_change']).transpose()\n",
    "            ds_lt_change.append(lt_change)\n",
    "            \n",
    "# concatenate all signatures \n",
    "dataset = pd.concat([pd.concat(ds_ref_magnitude),\n",
    "                     pd.concat(ds_peak_water_year),\n",
    "                     pd.concat(ds_peak_water_magnitude),\n",
    "                     pd.concat(ds_peak_water_duration),\n",
    "                     pd.concat(ds_interannual_var),\n",
    "                     pd.concat(ds_seasonal_cont),\n",
    "                     pd.concat(ds_seasonal_var),\n",
    "                     pd.concat(ds_seasonal_shift),\n",
    "                     pd.concat(ds_lt_trend),\n",
    "                     pd.concat(ds_lt_change)])\n",
    "                         \n",
    "dataset.to_csv(\"/home/rooda/Dropbox/Patagonia/MS2 Results/dataset_hydro_signatures.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
